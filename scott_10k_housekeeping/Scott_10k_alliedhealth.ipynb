{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a42d93-f0a4-4a89-83c1-27952324f5c5",
   "metadata": {},
   "source": [
    "## Scott 10K Allied health dataset\n",
    "\n",
    "### Aim: Obtain demographic, clinical and neuroimaging (T1 file paths, MWC1T1 file paths) for the scans\n",
    "\n",
    "### First order of business: create the .txt file of all ADNI T1 patients I want in my table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efc06ae-1c24-4b37-8b82-abaa4bb73096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15733\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "mydir=/rds/general/project/scott_data_adni/live/ADNI/ADNI_NIFTI/\n",
    "output_file=/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_t1_paths.txt\n",
    ">\"$output_file\"\n",
    "find \"$mydir\" -type f -name \"*.nii.gz\" >> \"$output_file\"\n",
    "\n",
    "wc -l<\"${output_file}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688a3730-1a4c-41e6-b4f5-f4ea634fb495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID</th>\n",
       "      <th>DATA_KEY</th>\n",
       "      <th>T1_YEAR</th>\n",
       "      <th>T1_MON</th>\n",
       "      <th>T1_DAY</th>\n",
       "      <th>VISDATE</th>\n",
       "      <th>EXAMDATE_4WKS_LATER</th>\n",
       "      <th>EXAMDATE_4WKS_B4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2012-11-05_12_04_44.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-11-05</td>\n",
       "      <td>2012-12-03</td>\n",
       "      <td>2012-10-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2012-07-24_09_50_58.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>2012-08-21</td>\n",
       "      <td>2012-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2013-08-26_14_02_58.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2013-08-26</td>\n",
       "      <td>2013-09-23</td>\n",
       "      <td>2013-07-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2013-02-25_13_24_41.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>2013-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>941_S_6471</td>\n",
       "      <td>6471</td>\n",
       "      <td>941_S_6471_ADNI-T1_2020-09-01_12_46_08.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15728</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2006-05-31_13_21_45.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>2006-06-28</td>\n",
       "      <td>2006-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15729</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2007-02-08_16_25_18.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>2007-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15730</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2006-05-31_13_29_57.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>2006-06-28</td>\n",
       "      <td>2006-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15731</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2007-02-08_16_33_35.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>2007-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15732</th>\n",
       "      <td>014_S_6944</td>\n",
       "      <td>6944</td>\n",
       "      <td>014_S_6944_ADNI-T1_2021-06-02_10_04_58.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-05-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15733 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PTID   RID                                  DATA_KEY  T1_YEAR  \\\n",
       "0      012_S_4849  4849  012_S_4849_ADNI-T1_2012-11-05_12_04_44.0   2012.0   \n",
       "1      012_S_4849  4849  012_S_4849_ADNI-T1_2012-07-24_09_50_58.0   2012.0   \n",
       "2      012_S_4849  4849  012_S_4849_ADNI-T1_2013-08-26_14_02_58.0   2013.0   \n",
       "3      012_S_4849  4849  012_S_4849_ADNI-T1_2013-02-25_13_24_41.0   2013.0   \n",
       "4      941_S_6471  6471  941_S_6471_ADNI-T1_2020-09-01_12_46_08.0   2020.0   \n",
       "...           ...   ...                                       ...      ...   \n",
       "15728  073_S_0312  0312  073_S_0312_ADNI-T1_2006-05-31_13_21_45.0   2006.0   \n",
       "15729  073_S_0312  0312  073_S_0312_ADNI-T1_2007-02-08_16_25_18.0   2007.0   \n",
       "15730  073_S_0312  0312  073_S_0312_ADNI-T1_2006-05-31_13_29_57.0   2006.0   \n",
       "15731  073_S_0312  0312  073_S_0312_ADNI-T1_2007-02-08_16_33_35.0   2007.0   \n",
       "15732  014_S_6944  6944  014_S_6944_ADNI-T1_2021-06-02_10_04_58.0   2021.0   \n",
       "\n",
       "       T1_MON  T1_DAY    VISDATE EXAMDATE_4WKS_LATER EXAMDATE_4WKS_B4  \n",
       "0        11.0     5.0 2012-11-05          2012-12-03       2012-10-08  \n",
       "1         7.0    24.0 2012-07-24          2012-08-21       2012-06-26  \n",
       "2         8.0    26.0 2013-08-26          2013-09-23       2013-07-29  \n",
       "3         2.0    25.0 2013-02-25          2013-03-25       2013-01-28  \n",
       "4         9.0     1.0 2020-09-01          2020-09-29       2020-08-04  \n",
       "...       ...     ...        ...                 ...              ...  \n",
       "15728     5.0    31.0 2006-05-31          2006-06-28       2006-05-03  \n",
       "15729     2.0     8.0 2007-02-08          2007-03-08       2007-01-11  \n",
       "15730     5.0    31.0 2006-05-31          2006-06-28       2006-05-03  \n",
       "15731     2.0     8.0 2007-02-08          2007-03-08       2007-01-11  \n",
       "15732     6.0     2.0 2021-06-02          2021-06-30       2021-05-05  \n",
       "\n",
       "[15733 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "t1_paths = '/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_t1_paths.txt'\n",
    "patient_id_list = []\n",
    "rid_list = []\n",
    "data_key_list = []\n",
    "t1_year_list = []\n",
    "t1_mon_list = []\n",
    "t1_day_list = []\n",
    "visdate_list = []\n",
    "\n",
    "with open(t1_paths,'r') as paths:\n",
    "    all_paths = paths.readlines()\n",
    "    for path in all_paths:\n",
    "        path_parts = path.split('/')\n",
    "        patient = path_parts[-1].strip('.nii.gz\\n')\n",
    "\n",
    "        patient_parts = patient.split('_')\n",
    "        data_key = '_'.join(patient_parts)\n",
    "        data_key_list.append(data_key)\n",
    "    \n",
    "        patient_id = '_'.join(patient_parts[:3])\n",
    "        rid = patient_id.split('_')[-1]\n",
    "        rid_list.append(rid)\n",
    "        patient_id_list.append(patient_id)\n",
    "    \n",
    "        try:\n",
    "            t1_date = patient_parts[4]\n",
    "            t1_year, t1_mon, t1_day = t1_date.split('-')\n",
    "            t1_year_list.append(t1_year)\n",
    "            t1_mon_list.append(t1_mon)\n",
    "            t1_day_list.append(t1_day)\n",
    "            visdate_list.append(f\"{t1_year}-{t1_mon}-{t1_day}\")\n",
    "        except (IndexError, ValueError):\n",
    "            t1_year_list.append(np.nan)\n",
    "            t1_mon_list.append(np.nan)\n",
    "            t1_day_list.append(np.nan)\n",
    "            visdate_list.append(np.nan)\n",
    "        \n",
    "df = {\n",
    "    \"PTID\" : patient_id_list,\n",
    "    \"RID\" : rid_list,\n",
    "    \"DATA_KEY\" : data_key_list,\n",
    "    \"T1_YEAR\" : t1_year_list,\n",
    "    \"T1_MON\" : t1_mon_list,\n",
    "    \"T1_DAY\" : t1_day_list,\n",
    "    \"VISDATE_STR\" : visdate_list\n",
    "}\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "df['T1_YEAR'] = pd.to_numeric(df['T1_YEAR'], errors='coerce')\n",
    "df['T1_MON'] = pd.to_numeric(df['T1_MON'], errors='coerce')\n",
    "df['T1_DAY'] = pd.to_numeric(df['T1_DAY'], errors='coerce')\n",
    "\n",
    "df['VISDATE'] = pd.to_datetime(df['VISDATE_STR'], errors='coerce')\n",
    "df = df.drop(columns=['VISDATE_STR'])\n",
    "\n",
    "df['EXAMDATE_4WKS_LATER'] = df['VISDATE'] + timedelta(weeks = 4)\n",
    "df['EXAMDATE_4WKS_B4'] = df['VISDATE'] - timedelta(weeks = 4)\n",
    "\n",
    "df      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d601c4-0bdb-46e3-af67-6c0064a59326",
   "metadata": {},
   "source": [
    "### Time to add T1 paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0509a3-18aa-4089-b8a5-b9d6b50831a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID</th>\n",
       "      <th>DATA_KEY</th>\n",
       "      <th>T1_YEAR</th>\n",
       "      <th>T1_MON</th>\n",
       "      <th>T1_DAY</th>\n",
       "      <th>VISDATE</th>\n",
       "      <th>EXAMDATE_4WKS_LATER</th>\n",
       "      <th>EXAMDATE_4WKS_B4</th>\n",
       "      <th>T1_PATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2012-11-05_12_04_44.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-11-05</td>\n",
       "      <td>2012-12-03</td>\n",
       "      <td>2012-10-08</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2012-07-24_09_50_58.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>2012-08-21</td>\n",
       "      <td>2012-06-26</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2013-08-26_14_02_58.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2013-08-26</td>\n",
       "      <td>2013-09-23</td>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2013-02-25_13_24_41.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>941_S_6471</td>\n",
       "      <td>6471</td>\n",
       "      <td>941_S_6471_ADNI-T1_2020-09-01_12_46_08.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15728</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2006-05-31_13_21_45.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>2006-06-28</td>\n",
       "      <td>2006-05-03</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15729</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2007-02-08_16_25_18.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15730</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2006-05-31_13_29_57.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>2006-06-28</td>\n",
       "      <td>2006-05-03</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15731</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2007-02-08_16_33_35.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15732</th>\n",
       "      <td>014_S_6944</td>\n",
       "      <td>6944</td>\n",
       "      <td>014_S_6944_ADNI-T1_2021-06-02_10_04_58.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15733 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PTID   RID                                  DATA_KEY  T1_YEAR  \\\n",
       "0      012_S_4849  4849  012_S_4849_ADNI-T1_2012-11-05_12_04_44.0   2012.0   \n",
       "1      012_S_4849  4849  012_S_4849_ADNI-T1_2012-07-24_09_50_58.0   2012.0   \n",
       "2      012_S_4849  4849  012_S_4849_ADNI-T1_2013-08-26_14_02_58.0   2013.0   \n",
       "3      012_S_4849  4849  012_S_4849_ADNI-T1_2013-02-25_13_24_41.0   2013.0   \n",
       "4      941_S_6471  6471  941_S_6471_ADNI-T1_2020-09-01_12_46_08.0   2020.0   \n",
       "...           ...   ...                                       ...      ...   \n",
       "15728  073_S_0312  0312  073_S_0312_ADNI-T1_2006-05-31_13_21_45.0   2006.0   \n",
       "15729  073_S_0312  0312  073_S_0312_ADNI-T1_2007-02-08_16_25_18.0   2007.0   \n",
       "15730  073_S_0312  0312  073_S_0312_ADNI-T1_2006-05-31_13_29_57.0   2006.0   \n",
       "15731  073_S_0312  0312  073_S_0312_ADNI-T1_2007-02-08_16_33_35.0   2007.0   \n",
       "15732  014_S_6944  6944  014_S_6944_ADNI-T1_2021-06-02_10_04_58.0   2021.0   \n",
       "\n",
       "       T1_MON  T1_DAY    VISDATE EXAMDATE_4WKS_LATER EXAMDATE_4WKS_B4  \\\n",
       "0        11.0     5.0 2012-11-05          2012-12-03       2012-10-08   \n",
       "1         7.0    24.0 2012-07-24          2012-08-21       2012-06-26   \n",
       "2         8.0    26.0 2013-08-26          2013-09-23       2013-07-29   \n",
       "3         2.0    25.0 2013-02-25          2013-03-25       2013-01-28   \n",
       "4         9.0     1.0 2020-09-01          2020-09-29       2020-08-04   \n",
       "...       ...     ...        ...                 ...              ...   \n",
       "15728     5.0    31.0 2006-05-31          2006-06-28       2006-05-03   \n",
       "15729     2.0     8.0 2007-02-08          2007-03-08       2007-01-11   \n",
       "15730     5.0    31.0 2006-05-31          2006-06-28       2006-05-03   \n",
       "15731     2.0     8.0 2007-02-08          2007-03-08       2007-01-11   \n",
       "15732     6.0     2.0 2021-06-02          2021-06-30       2021-05-05   \n",
       "\n",
       "                                                 T1_PATH  \n",
       "0      /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "1      /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "2      /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "3      /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "4      /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "...                                                  ...  \n",
       "15728  /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "15729  /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "15730  /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "15731  /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "15732  /rds/general/project/scott_data_adni/live/ADNI...  \n",
       "\n",
       "[15733 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1_paths = '/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_t1_paths.txt'\n",
    "key_to_path = {}\n",
    "\n",
    "with open(t1_paths,'r') as paths:\n",
    "    all_paths = paths.readlines()\n",
    "    for path in all_paths:\n",
    "        path  = path.strip('\\n')\n",
    "        raw_key = path.split('/')[-1]\n",
    "        key = raw_key.replace('.nii.gz','')\n",
    "        key_to_path[key] = path\n",
    "\n",
    "df['T1_PATH'] = df['DATA_KEY'].map(key_to_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90055b06-7e6a-4bc8-a14c-15bc64052ef6",
   "metadata": {},
   "source": [
    "### Now for mwc1t1 paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c564826b-008c-450a-8297-1748693f6ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15726\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "mydir=/rds/general/project/c3nl_scott_students/live/data/sankeith/scott_10k_b2c/\n",
    "output_file=/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/successful_scott_10k_mwc1t1_paths.txt\n",
    "\n",
    "### collect mwc1t1 file paths##\n",
    "\n",
    ">\"$output_file\"\n",
    "find \"$mydir\" -type f -name \"mwc1t1*\" >> \"$output_file\"\n",
    "wc -l<\"${output_file}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3e0afe-da0e-4d86-b06e-a7976f22bdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PTID</th>\n",
       "      <th>RID</th>\n",
       "      <th>DATA_KEY</th>\n",
       "      <th>T1_YEAR</th>\n",
       "      <th>T1_MON</th>\n",
       "      <th>T1_DAY</th>\n",
       "      <th>VISDATE</th>\n",
       "      <th>EXAMDATE_4WKS_LATER</th>\n",
       "      <th>EXAMDATE_4WKS_B4</th>\n",
       "      <th>T1_PATH</th>\n",
       "      <th>MWC1T1_PATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2012-11-05_12_04_44.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-11-05</td>\n",
       "      <td>2012-12-03</td>\n",
       "      <td>2012-10-08</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2012-07-24_09_50_58.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2012-07-24</td>\n",
       "      <td>2012-08-21</td>\n",
       "      <td>2012-06-26</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2013-08-26_14_02_58.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2013-08-26</td>\n",
       "      <td>2013-09-23</td>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>012_S_4849</td>\n",
       "      <td>4849</td>\n",
       "      <td>012_S_4849_ADNI-T1_2013-02-25_13_24_41.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>941_S_6471</td>\n",
       "      <td>6471</td>\n",
       "      <td>941_S_6471_ADNI-T1_2020-09-01_12_46_08.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15728</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2006-05-31_13_21_45.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>2006-06-28</td>\n",
       "      <td>2006-05-03</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15729</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2007-02-08_16_25_18.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15730</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2006-05-31_13_29_57.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2006-05-31</td>\n",
       "      <td>2006-06-28</td>\n",
       "      <td>2006-05-03</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15731</th>\n",
       "      <td>073_S_0312</td>\n",
       "      <td>0312</td>\n",
       "      <td>073_S_0312_ADNI-T1_2007-02-08_16_33_35.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2007-02-08</td>\n",
       "      <td>2007-03-08</td>\n",
       "      <td>2007-01-11</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15732</th>\n",
       "      <td>014_S_6944</td>\n",
       "      <td>6944</td>\n",
       "      <td>014_S_6944_ADNI-T1_2021-06-02_10_04_58.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>/rds/general/project/scott_data_adni/live/ADNI...</td>\n",
       "      <td>/rds/general/project/c3nl_scott_students/live/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15733 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PTID   RID                                  DATA_KEY  T1_YEAR  \\\n",
       "0      012_S_4849  4849  012_S_4849_ADNI-T1_2012-11-05_12_04_44.0   2012.0   \n",
       "1      012_S_4849  4849  012_S_4849_ADNI-T1_2012-07-24_09_50_58.0   2012.0   \n",
       "2      012_S_4849  4849  012_S_4849_ADNI-T1_2013-08-26_14_02_58.0   2013.0   \n",
       "3      012_S_4849  4849  012_S_4849_ADNI-T1_2013-02-25_13_24_41.0   2013.0   \n",
       "4      941_S_6471  6471  941_S_6471_ADNI-T1_2020-09-01_12_46_08.0   2020.0   \n",
       "...           ...   ...                                       ...      ...   \n",
       "15728  073_S_0312  0312  073_S_0312_ADNI-T1_2006-05-31_13_21_45.0   2006.0   \n",
       "15729  073_S_0312  0312  073_S_0312_ADNI-T1_2007-02-08_16_25_18.0   2007.0   \n",
       "15730  073_S_0312  0312  073_S_0312_ADNI-T1_2006-05-31_13_29_57.0   2006.0   \n",
       "15731  073_S_0312  0312  073_S_0312_ADNI-T1_2007-02-08_16_33_35.0   2007.0   \n",
       "15732  014_S_6944  6944  014_S_6944_ADNI-T1_2021-06-02_10_04_58.0   2021.0   \n",
       "\n",
       "       T1_MON  T1_DAY    VISDATE EXAMDATE_4WKS_LATER EXAMDATE_4WKS_B4  \\\n",
       "0        11.0     5.0 2012-11-05          2012-12-03       2012-10-08   \n",
       "1         7.0    24.0 2012-07-24          2012-08-21       2012-06-26   \n",
       "2         8.0    26.0 2013-08-26          2013-09-23       2013-07-29   \n",
       "3         2.0    25.0 2013-02-25          2013-03-25       2013-01-28   \n",
       "4         9.0     1.0 2020-09-01          2020-09-29       2020-08-04   \n",
       "...       ...     ...        ...                 ...              ...   \n",
       "15728     5.0    31.0 2006-05-31          2006-06-28       2006-05-03   \n",
       "15729     2.0     8.0 2007-02-08          2007-03-08       2007-01-11   \n",
       "15730     5.0    31.0 2006-05-31          2006-06-28       2006-05-03   \n",
       "15731     2.0     8.0 2007-02-08          2007-03-08       2007-01-11   \n",
       "15732     6.0     2.0 2021-06-02          2021-06-30       2021-05-05   \n",
       "\n",
       "                                                 T1_PATH  \\\n",
       "0      /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "1      /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "2      /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "3      /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "4      /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "...                                                  ...   \n",
       "15728  /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "15729  /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "15730  /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "15731  /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "15732  /rds/general/project/scott_data_adni/live/ADNI...   \n",
       "\n",
       "                                             MWC1T1_PATH  \n",
       "0      /rds/general/project/c3nl_scott_students/live/...  \n",
       "1      /rds/general/project/c3nl_scott_students/live/...  \n",
       "2      /rds/general/project/c3nl_scott_students/live/...  \n",
       "3      /rds/general/project/c3nl_scott_students/live/...  \n",
       "4      /rds/general/project/c3nl_scott_students/live/...  \n",
       "...                                                  ...  \n",
       "15728  /rds/general/project/c3nl_scott_students/live/...  \n",
       "15729  /rds/general/project/c3nl_scott_students/live/...  \n",
       "15730  /rds/general/project/c3nl_scott_students/live/...  \n",
       "15731  /rds/general/project/c3nl_scott_students/live/...  \n",
       "15732  /rds/general/project/c3nl_scott_students/live/...  \n",
       "\n",
       "[15733 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mwc1t1_paths = '/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/successful_scott_10k_mwc1t1_paths.txt'\n",
    "key_to_path = {}\n",
    "\n",
    "with open(mwc1t1_paths,'r') as paths:\n",
    "    all_paths = paths.readlines()\n",
    "    for path in all_paths:\n",
    "        path  = path.strip('\\n')\n",
    "        key = path.split('/')[-2]\n",
    "        key_to_path[key] = path\n",
    "\n",
    "df['MWC1T1_PATH'] = df['DATA_KEY'].map(key_to_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52203c00-4c04-4d41-96c6-7e55d25f1036",
   "metadata": {},
   "source": [
    "#### How many unique patients are there (as measured by PTID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1fb52f2-c8ce-4f29-be92-81ae70cab9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2635"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['PTID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed58f4aa-dbb7-483a-90ff-d123f813cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/interim_scott_10k_alliedhealth.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc2895-b94c-4ce1-b7b5-ebe6bce366d5",
   "metadata": {},
   "source": [
    "### Make a .m file of Greg's code, and run that. This gets us patient demographics (Gender, Date of Birth and Education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "919fa40c-8fa9-43b1-8688-fe5ed4248af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_add_demographics_info.m\n"
     ]
    }
   ],
   "source": [
    "%%file /rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_add_demographics_info.m\n",
    "\n",
    "T=readtable('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/interim_scott_10k_alliedhealth.csv');\n",
    "save('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/interim_scott_10k_alliedhealth.mat');\n",
    "\n",
    "data = load('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/interim_scott_10k_alliedhealth.mat');\n",
    "head(data.T) %% shows data = struct with fields, and T = [15733 x 11]\n",
    "disp(data)\n",
    "\n",
    "%% This has most of Greg's code. I'm not going to vectorise it\n",
    "\n",
    "basepath = '/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/'\n",
    "\n",
    "vars = { ...\n",
    "    {'/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/PTDEMOG_10Sep2025.csv', {'PTGENDER', 'PTDOB', 'PTEDUCAT'}, {NaN, NaT, NaN}, {[], @(x) datetime(x, 'InputFormat', 'MM/yyyy'),[] }}};\n",
    "\n",
    "for v=1:numel(vars) %%opens the relevant CSV, and makes sure that VISDATE is a column. If not, then it duplicates EXAMDATE and calls it VISDATE.\n",
    "    Talli = readtable(vars{v}{1});\n",
    "    Talli.PTID = string(Talli.PTID);\n",
    "    if(~ismember('VISDATE', Talli.Properties.VariableNames))\n",
    "        Talli.VISDATE = Talli.EXAMDATE;\n",
    "    end\n",
    "   \n",
    "    fprintf('joining file %s, rows=%d\\n', vars{v}{1}, height(Talli));\n",
    "    \n",
    "    varNames = vars{v}{2}; %%selects the appropriate columns from the relevant CSV\n",
    "    if(~isempty(vars{v}{3}))\n",
    "        fprintf('(setting types)\\n');\n",
    "        for vf=1:numel(vars{v}{3})\n",
    "             T{:,varNames{vf}} = repmat(vars{v}{3}{vf}, height(T), 1); %% padding missing values with NaNs or NaTs\n",
    "        end\n",
    "    else\n",
    "        T{:,varNames} = nan(height(T),numel(varNames)); %%also padding missing values, but this is for the case where there a column entirely contains missing values\n",
    "    end\n",
    "    \n",
    "    if(~isempty(vars{v}{4})) %%setting the appropriate date format (e.g., datetime)\n",
    "        fprintf('(converting)\\n');\n",
    "        for vf=1:numel(vars{v}{4})\n",
    "            if(~isempty(vars{v}{4}{vf}))\n",
    "                Talli.(vars{v}{2}{vf}) = vars{v}{4}{vf}(Talli.(vars{v}{2}{vf}));\n",
    "            end\n",
    "        end\n",
    "        fprintf('(done)\\n')\n",
    "    end\n",
    "\n",
    "    for s=1:height(T)\n",
    "        Tsub = Talli(Talli.PTID == T.PTID(s),:);\n",
    "        if(~isempty(Tsub))\n",
    "            Tsub.datediffs = abs(days( (Tsub.VISDATE - T.VISDATE(s))));\n",
    "            Tsub = sortrows(Tsub, 'datediffs', 'asc'); % order so that the one nearest the imaging appears 1st\n",
    "            T(s, varNames) = Tsub(1,varNames);\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "fprintf('Width: %d Height: %d\\n', width(T), height(T))\n",
    "writetable(T, '/rds/general/project/c3nl_scott_students/ephemeral/sankeith/gregbased_scott10k_alliedhealth.csv')\n",
    "\n",
    "if isfile('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/gregbased_scott10k_alliedhealth.csv')\n",
    "    disp('Demographics data joined')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1ee299d-7ffd-4920-abba-49e59b0c5294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_add_demographics_info.sh\n"
     ]
    }
   ],
   "source": [
    "%%file /rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_add_demographics_info.sh\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "module load tools/prod\n",
    "module --ignore_cache load MATLAB2024/b > /dev/null 2>&1\n",
    "\n",
    "matlab -nosplash -nodesktop -r \"run('/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_add_demographics_info.m'); exit\"\n",
    "\n",
    "rm /rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_add_demographics_info.* \n",
    "rm -f ~/java* ~/*crash*dump*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cb3bcb5-a105-4a76-951b-377ca1d071ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATLAB is selecting SOFTWARE OPENGL rendering.\n",
      "Opening log file:  /rds/general/user/sk4724/home/java.log.12346\n",
      "\n",
      " L A B (R) >                < M A T\n",
      "                  Copyright 1984-2023 The MathWorks, Inc.\n",
      "2.0.2365128) 64-bit (glnxa64)\n",
      "                              August 23, 2023\n",
      "\n",
      " \n",
      "To get started, type doc.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      "         PTID         RID                       DATA_KEY                      T1_YEAR    T1_MON    T1_DAY      VISDATE      EXAMDATE_4WKS_LATER    EXAMDATE_4WKS_B4                                                                             T1_PATH                                                                                                                                                 MWC1T1_PATH                                                                    \n",
      "    ______________    ____    ____________________________________________    _______    ______    ______    ___________    ___________________    ________________    _________________________________________________________________________________________________________________________________________________________    ___________________________________________________________________________________________________________________________________________________\n",
      "\n",
      "    {'012_S_4849'}    4849    {'012_S_4849_ADNI-T1_2012-11-05_12_04_44.0'}     2012        11         5      05-Nov-2012        03-Dec-2012          08-Oct-2012       {'/rds/general/project/scott_data_adni/live/ADNI/ADNI_NIFTI/ADNI_allT1/012_S_4849/2012-11-05_12_04_44.0/012_S_4849_ADNI-T1_2012-11-05_12_04_44.0.nii.gz'}    {'/rds/general/project/c3nl_scott_students/live/data/sankeith/scott_10k_b2c/012_S_4849_ADNI-T1_2012-11-05_12_04_44.0/mwc1t1_reoriented_fsl.nii.gz'}\n",
      "    {'012_S_4849'}    4849    {'012_S_4849_ADNI-T1_2012-07-24_09_50_58.0'}     2012         7        24      24-Jul-2012        21-Aug-2012          26-Jun-2012       {'/rds/general/project/scott_data_adni/live/ADNI/ADNI_NIFTI/ADNI_allT1/012_S_4849/2012-07-24_09_50_58.0/012_S_4849_ADNI-T1_2012-07-24_09_50_58.0.nii.gz'}    {'/rds/general/project/c3nl_scott_students/live/data/sankeith/scott_10k_b2c/012_S_4849_ADNI-T1_2012-07-24_09_50_58.0/mwc1t1_reoriented_fsl.nii.gz'}\n",
      "    {'012_S_4849'}    4849    {'012_S_4849_ADNI-T1_2013-08-26_14_02_58.0'}     2013         8        26      26-Aug-2013        23-Sep-2013          29-Jul-2013       {'/rds/general/project/scott_data_adni/live/ADNI/ADNI_NIFTI/ADNI_allT1/012_S_4849/2013-08-26_14_02_58.0/012_S_4849_ADNI-T1_2013-08-26_14_02_58.0.nii.gz'}    {'/rds/general/project/c3nl_scott_students/live/data/sankeith/scott_10k_b2c/012_S_4849_ADNI-T1_2013-08-26_14_02_58.0/mwc1t1_reoriented_fsl.nii.gz'}\n",
      "    {'012_S_4849'}    4849    {'012_S_4849_ADNI-T1_2013-02-25_13_24_41.0'}     2013         2        25      25-Feb-2013        25-Mar-2013          28-Jan-2013       {'/rds/general/project/scott_data_adni/live/ADNI/ADNI_NIFTI/ADNI_allT1/012_S_4849/2013-02-25_13_24_41.0/012_S_4849_ADNI-T1_2013-02-25_13_24_41.0.nii.gz'}    {'/rds/general/project/c3nl_scott_students/live/data/sankeith/scott_10k_b2c/012_S_4849_ADNI-T1_2013-02-25_13_24_41.0/mwc1t1_reoriented_fsl.nii.gz'}\n",
      "    {'941_S_6471'}    6471    {'941_S_6471_ADNI-T1_2020-09-01_12_46_08.0'}     2020         9         1      01-Sep-2020        29-Sep-2020          04-Aug-2020       {'/rds/general/project/scott_data_adni/live/ADNI/ADNI_NIFTI/ADNI_allT1/941_S_6471/2020-09-01_12_46_08.0/941_S_6471_ADNI-T1_2020-09-01_12_46_08.0.nii.gz'}    {'/rds/general/project/c3nl_scott_students/live/data/sankeith/scott_10k_b2c/941_S_6471_ADNI-T1_2020-09-01_12_46_08.0/mwc1t1_reoriented_fsl.nii.gz'}\n",
      "    {'941_S_6471'}    6471    {'941_S_6471_ADNI-T1_2022-08-24_12_19_00.0'}     2022         8        24      24-Aug-2022        21-Sep-2022          27-Jul-2022       {'/rds/general/project/scott_data_adni/live/ADNI/ADNI_NIFTI/ADNI_allT1/941_S_6471/2022-08-24_12_19_00.0/941_S_6471_ADNI-T1_2022-08-24_12_19_00.0.nii.gz'}    {'/rds/general/project/c3nl_scott_students/live/data/sankeith/scott_10k_b2c/941_S_6471_ADNI-T1_2022-08-24_12_19_00.0/mwc1t1_reoriented_fsl.nii.gz'}\n",
      "    {'941_S_6471'}    6471    {'941_S_6471_ADNI-T1_2018-07-02_09_58_08.0'}     2018         7         2      02-Jul-2018        30-Jul-2018          04-Jun-2018       {'/rds/general/project/scott_data_adni/live/ADNI/ADNI_NIFTI/ADNI_allT1/941_S_6471/2018-07-02_09_58_08.0/941_S_6471_ADNI-T1_2018-07-02_09_58_08.0.nii.gz'}    {'/rds/general/project/c3nl_scott_students/live/data/sankeith/scott_10k_b2c/941_S_6471_ADNI-T1_2018-07-02_09_58_08.0/mwc1t1_reoriented_fsl.nii.gz'}\n",
      "    {'037_S_6125'}    6125    {'037_S_6125_ADNI-T1_2019-03-25_15_17_16.0'}     2019         3        25      25-Mar-2019        22-Apr-2019          25-Feb-2019       {'/rds/general/project/scott_data_adni/live/ADNI/ADNI_NIFTI/ADNI_allT1/037_S_6125/2019-03-25_15_17_16.0/037_S_6125_ADNI-T1_2019-03-25_15_17_16.0.nii.gz'}    {'/rds/general/project/c3nl_scott_students/live/data/sankeith/scott_10k_b2c/037_S_6125_ADNI-T1_2019-03-25_15_17_16.0/mwc1t1_reoriented_fsl.nii.gz'}\n",
      "\n",
      "    T: [15733x11 table]\n",
      "\n",
      "\n",
      "basepath =\n",
      "\n",
      "t_10k_extra_adni_info/'ct/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scot\n",
      "\n",
      "joining file /rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/PTDEMOG_10Sep2025.csv, rows=6199\n",
      "(setting types)\n",
      "(converting)\n",
      "(done)\n",
      "Width: 14 Height: 15733\n",
      "Demographics data joined\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "chmod -Rf 775 /rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_add_demographics_info.*\n",
    "\n",
    "/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_add_demographics_info.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f00cc-965e-4b66-83c5-a3d03011a783",
   "metadata": {},
   "source": [
    "### Load in time-sensitive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c2471cf-c6a2-4ea9-8319-e7f2b188ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import fnmatch\n",
    "import warnings\n",
    "import math\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4595e21c-f6a0-44e1-a2f9-b470126ddbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15733\n",
      "15\n",
      "2635\n",
      "count    15314.000000\n",
      "mean        74.907797\n",
      "std          7.383833\n",
      "min         50.000000\n",
      "25%         70.000000\n",
      "50%         75.000000\n",
      "75%         80.000000\n",
      "max        102.000000\n",
      "Name: PTAGE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/gregbased_scott10k_alliedhealth.csv', low_memory = False)\n",
    "df[f'VISDATE'] = pd.to_datetime(df[f'VISDATE'])\n",
    "df[f'EXAMDATE_4WKS_LATER'] = pd.to_datetime(df[f'EXAMDATE_4WKS_LATER'])\n",
    "df[f'EXAMDATE_4WKS_B4'] = pd.to_datetime(df[f'EXAMDATE_4WKS_B4'])\n",
    "df[f'PTDOB'] = pd.to_datetime(df[f'PTDOB'])\n",
    "df[f'PTAGE_YEARS'] = df['VISDATE'] - df['PTDOB']\n",
    "df[f'PTAGE'] = df[f'PTAGE_YEARS'] / timedelta(days = 365)\n",
    "def floor_years(n):\n",
    "    try:\n",
    "        return math.floor(n)\n",
    "    except ValueError:\n",
    "        return n\n",
    "df[f'PTAGE'] = df[f'PTAGE'].apply(lambda x: floor_years(x))\n",
    "df.drop(columns = 'PTAGE_YEARS', inplace = True)\n",
    "print(len(df))\n",
    "print(len(df.columns))\n",
    "print(len(df['PTID'].unique()))\n",
    "print(df[f'PTAGE'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab750bf-311e-47bb-9996-0ffe002bdb91",
   "metadata": {},
   "source": [
    "### Merge APOE Genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fc67bad-a51c-4eb1-ba4b-0a0096360e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            PTID GENOTYPE\n",
      "0     011_S_0002      3/3\n",
      "1     011_S_0003      3/4\n",
      "2     022_S_0004      3/3\n",
      "3     011_S_0005      3/3\n",
      "4     022_S_0007      3/4\n",
      "...          ...      ...\n",
      "2755  341_S_7018      3/3\n",
      "2756  035_S_7019      3/3\n",
      "2757  052_S_7027      4/4\n",
      "2758  941_S_7041      3/4\n",
      "2759  035_S_7049      3/3\n",
      "\n",
      "[2760 rows x 2 columns]\n",
      "15733\n"
     ]
    }
   ],
   "source": [
    "apoe_df = pd.read_csv('/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/APOERES_28Mar2025.csv',low_memory = False)[['PTID','GENOTYPE']]\n",
    "apoe_df.drop_duplicates(subset = ['PTID','GENOTYPE'], inplace = True)\n",
    "print(apoe_df)\n",
    "df = df.merge(apoe_df, how = 'left', on = ['PTID'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999a81d-1450-400f-a1d4-cf945e596013",
   "metadata": {},
   "source": [
    "### Prepping ADAS13 DataFrame and MRI FIELD STRENGTH DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07ac80fa-cbbc-4cd6-a868-cc0d6c3abcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11618\n",
      "13933\n",
      "742\n"
     ]
    }
   ],
   "source": [
    "### Prepping ADAS123 DataFrame ###\n",
    "adas_adni1_df = pd.read_csv('/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/ADASSCORES_01Apr2025.csv', low_memory = False)[['PTID','EXAMDATE','TOTALMOD']]\n",
    "adas_adni1_df.rename(columns={'TOTALMOD': 'TOTAL13', 'EXAMDATE': 'VISDATE'}, inplace=True)\n",
    "\n",
    "adas_adnigo23_df = pd.read_csv('/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/ADAS_ADNIGO23_31Mar2025.csv', low_memory = False)\n",
    "adas_adnigo23_df = adas_adnigo23_df[['PTID','VISDATE','TOTAL13']]\n",
    "\n",
    "adas_df = pd.concat([adas_adni1_df, adas_adnigo23_df], ignore_index=True)\n",
    "\n",
    "print(len(adas_df))\n",
    "\n",
    "adas_df.to_csv(f'/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/ADAS13_{datetime.datetime.now().strftime('%d%b%Y')}.csv', index = False)\n",
    "\n",
    "### Prepping MRI FIELD STRENGTH DataFrame ###\n",
    "\n",
    "mrimeta_df = pd.read_csv('/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/MRIMETA_11Sep2025.csv', low_memory = False)[['PTID','EXAMDATE','FIELD_STRENGTH']]\n",
    "mrimeta_3t_df = pd.read_csv('/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/MRI3META_11Sep2025.csv', low_memory = False)[['PTID','EXAMDATE','FIELD_STRENGTH']]\n",
    "mri_df = pd.concat([mrimeta_df, mrimeta_3t_df], ignore_index=True)\n",
    "print(len(mri_df))\n",
    "mri_df.to_csv(f'/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/MRIFLDSTRNGTH_{datetime.datetime.now().strftime('%d%b%Y')}.csv', index = False)\n",
    "\n",
    "### Prepping Amyloid DataFrame - I only use the batemanlab info which includes EXAMDATE (the other batemanlab DataFrame only has VISCODE, so can't join with Scott 10K) ###\n",
    "\n",
    "amyloid_df = pd.read_csv('/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/batemanlab_20221118_31Mar2025.csv', low_memory = False)[['RID' ,'EXAMDATE', 'Abeta_4240_Standardized', 'Intertcept_Standardization', 'Slope_Standardization', 'Sample_volume', 'Sample_volume_UNITS', 'Abeta_42_conc', 'Abeta_42_conc_UNITS', 'Abeta_42_N14N15', 'Abeta_42_N15_ISTD_amount', 'Abeta_42_N15_ISTD_amount_UNITS', 'Abeta_40_conc', 'Abeta_40_conc_UNITS', 'Abeta_40_N14N15', 'Abeta_40_N15_ISTD_amount', 'Abeta_40_N15_ISTD_amount_UNITS', 'Abeta_4240']]\n",
    "print(len(amyloid_df))\n",
    "amyloid_df.to_csv(f'/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/AMYLOID_{datetime.datetime.now().strftime('%d%b%Y')}.csv', index = False)\n",
    "\n",
    "### Prepping p217 tau DataFrame ###\n",
    "\n",
    "tau_df = pd.read_csv('/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/JANSSEN_PLASMA_P217_TAU_01Apr2025.csv', low_memory = False)[['PTID', 'EXAMDATE', 'DILUTION_CORRECTED_CONC', 'CV']]\n",
    "tau_df.rename(columns={'DILUTION_CORRECTED_CONC': 'P217_DILUTION_CORRECTED_CONC', 'CV': 'P217_CV'}, inplace=True)\n",
    "tau_df.to_csv(f'/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/P217_{datetime.datetime.now().strftime('%d%b%Y')}.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779bc3a8-b463-4168-bd5b-27d9ae30b38b",
   "metadata": {},
   "source": [
    "### Merging time-sensitive visit information (based on Greg's code):\n",
    "1. Load an allied health file\n",
    "2. Ensure allied health file as examdate\n",
    "3. Do a right type join (assume left = og file, right = allied health file)\n",
    "4. Extract rows only with a T1 file path, so we have full rows\n",
    "5. Calculate abs(allied health data - MRI visit date) and label it like df.datediffs or some shit\n",
    "6. df.groupby with PTID, and then sort by datediffs ascend\n",
    "7. Keep the row where datadiff is less than 28 days and the smallest val. If tie, then we ball and just choose at random\n",
    "8. Conduct a final length of rows check - MUST BE 15733\n",
    "9. Rinse and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e3c65eb-3a0f-40db-83ea-fb0792a912c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of MRIFLDSTRNGTH: 13933\n",
      "Length of the freshly joined dataframe: 118218\n",
      "After dropping rows without T1 paths: 118218\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_MRIFLDSTRNGTH are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_MRIFLDSTRNGTH > 28 days *OR* there is no EXAMDATE_MRIFLDSTRNGTH column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 16804. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 16796.\n",
      "There are 2126 rows with identical T1 MRI file paths, from 1063 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    15640.000000\n",
      "mean         0.037148\n",
      "std          0.697452\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max         28.000000\n",
      "Name: DATEDIFFS_MRIFLDSTRNGTH, dtype: float64\n",
      "\n",
      "Length of DXSUM: 15674\n",
      "Length of the freshly joined dataframe: 112212\n",
      "After dropping rows without T1 paths: 112212\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_DXSUM are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_DXSUM > 28 days *OR* there is no EXAMDATE_DXSUM column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15811. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15768.\n",
      "There are 70 rows with identical T1 MRI file paths, from 35 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    11932.000000\n",
      "mean         8.138451\n",
      "std          7.818778\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          6.000000\n",
      "75%         14.000000\n",
      "max         28.000000\n",
      "Name: DATEDIFFS_DXSUM, dtype: float64\n",
      "\n",
      "Length of MMSE: 14119\n",
      "Length of the freshly joined dataframe: 105119\n",
      "After dropping rows without T1 paths: 105119\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_MMSE are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_MMSE > 28 days *OR* there is no EXAMDATE_MMSE column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15755. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15733.\n",
      "There are 0 rows with identical T1 MRI file paths, from 0 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    13148.000000\n",
      "mean         5.750532\n",
      "std          7.505814\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%         10.000000\n",
      "max         28.000000\n",
      "Name: DATEDIFFS_MMSE, dtype: float64\n",
      "\n",
      "Length of MOCA: 8466\n",
      "Length of the freshly joined dataframe: 66487\n",
      "After dropping rows without T1 paths: 66487\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_MOCA are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_MOCA > 28 days *OR* there is no EXAMDATE_MOCA column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15745. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15733.\n",
      "There are 0 rows with identical T1 MRI file paths, from 0 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    6649.000000\n",
      "mean        5.625808\n",
      "std         7.579711\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%        10.000000\n",
      "max        28.000000\n",
      "Name: DATEDIFFS_MOCA, dtype: float64\n",
      "\n",
      "Length of NEUROBAT: 16837\n",
      "Length of the freshly joined dataframe: 120370\n",
      "After dropping rows without T1 paths: 120370\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_NEUROBAT are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_NEUROBAT > 28 days *OR* there is no EXAMDATE_NEUROBAT column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15877. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15847.\n",
      "There are 228 rows with identical T1 MRI file paths, from 114 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    13737.000000\n",
      "mean         5.438233\n",
      "std          6.934756\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%          9.000000\n",
      "max         28.000000\n",
      "Name: DATEDIFFS_NEUROBAT, dtype: float64\n",
      "\n",
      "Length of CDR: 14102\n",
      "Length of the freshly joined dataframe: 107905\n",
      "After dropping rows without T1 paths: 107905\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_CDR are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_CDR > 28 days *OR* there is no EXAMDATE_CDR column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15755. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15733.\n",
      "There are 0 rows with identical T1 MRI file paths, from 0 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    13070.000000\n",
      "mean         5.910023\n",
      "std          7.561881\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          2.000000\n",
      "75%         11.000000\n",
      "max         28.000000\n",
      "Name: DATEDIFFS_CDR, dtype: float64\n",
      "\n",
      "Length of FAQ: 12734\n",
      "Length of the freshly joined dataframe: 108123\n",
      "After dropping rows without T1 paths: 108123\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_FAQ are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_FAQ > 28 days *OR* there is no EXAMDATE_FAQ column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15750. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15734.\n",
      "There are 2 rows with identical T1 MRI file paths, from 1 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    12863.000000\n",
      "mean         5.814507\n",
      "std          7.552313\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%         10.000000\n",
      "max         28.000000\n",
      "Name: DATEDIFFS_FAQ, dtype: float64\n",
      "\n",
      "Length of NPIQ: 7176\n",
      "Length of the freshly joined dataframe: 71645\n",
      "After dropping rows without T1 paths: 71645\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_NPIQ are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_NPIQ > 28 days *OR* there is no EXAMDATE_NPIQ column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15767. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15734.\n",
      "There are 2 rows with identical T1 MRI file paths, from 1 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    7500.000000\n",
      "mean        5.560000\n",
      "std         7.371534\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.000000\n",
      "75%         9.000000\n",
      "max        28.000000\n",
      "Name: DATEDIFFS_NPIQ, dtype: float64\n",
      "\n",
      "Length of GDSCALE: 13201\n",
      "Length of the freshly joined dataframe: 95835\n",
      "After dropping rows without T1 paths: 95835\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_GDSCALE are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_GDSCALE > 28 days *OR* there is no EXAMDATE_GDSCALE column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15780. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15733.\n",
      "There are 0 rows with identical T1 MRI file paths, from 0 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    11225.000000\n",
      "mean         6.062094\n",
      "std          7.643121\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          2.000000\n",
      "75%         11.000000\n",
      "max         28.000000\n",
      "Name: DATEDIFFS_GDSCALE, dtype: float64\n",
      "\n",
      "Length of MODHACH: 3461\n",
      "Length of the freshly joined dataframe: 15733\n",
      "After dropping rows without T1 paths: 15733\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_MODHACH are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_MODHACH > 28 days *OR* there is no EXAMDATE_MODHACH column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15733. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15733.\n",
      "There are 0 rows with identical T1 MRI file paths, from 0 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    2899.000000\n",
      "mean       13.922732\n",
      "std         6.941904\n",
      "min         0.000000\n",
      "25%         9.000000\n",
      "50%        14.000000\n",
      "75%        19.000000\n",
      "max        28.000000\n",
      "Name: DATEDIFFS_MODHACH, dtype: float64\n",
      "\n",
      "Length of ADAS13: 11618\n",
      "Length of the freshly joined dataframe: 103099\n",
      "After dropping rows without T1 paths: 103099\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_ADAS13 are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_ADAS13 > 28 days *OR* there is no EXAMDATE_ADAS13 column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15746. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15734.\n",
      "There are 2 rows with identical T1 MRI file paths, from 1 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    12955.000000\n",
      "mean         5.681590\n",
      "std          7.540378\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%         10.000000\n",
      "max         28.000000\n",
      "Name: DATEDIFFS_ADAS13, dtype: float64\n",
      "\n",
      "Length of P217: 130\n",
      "Length of the freshly joined dataframe: 15830\n",
      "After dropping rows without T1 paths: 15830\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_P217 are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_P217 > 28 days *OR* there is no EXAMDATE_P217 column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 15733. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15733.\n",
      "There are 0 rows with identical T1 MRI file paths, from 0 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n",
      "Final row count: 15733\n",
      "Remaining duplicates: 0\n",
      "1    15733\n",
      "Name: count, dtype: int64\n",
      "count    107.000000\n",
      "mean       4.074766\n",
      "std        6.189920\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        1.000000\n",
      "75%        6.000000\n",
      "max       28.000000\n",
      "Name: DATEDIFFS_P217, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vars = [\n",
    "    [f'/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/MRIFLDSTRNGTH_{datetime.datetime.now().strftime('%d%b%Y')}.csv',['PTID','EXAMDATE','FIELD_STRENGTH'], {'FIELD_STRENGTH': pd.NA}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/DXSUM_10Sep2025.csv',['PTID','EXAMDATE','PHASE', 'DIAGNOSIS'], {'PHASE': pd.NA,'DIAGNOSIS':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/MMSE_28Mar2025.csv', ['PTID','VISDATE','MMSCORE'], {'MMSCORE':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/MOCA_30Mar2025.csv', ['PTID','VISDATE', 'MOCA'], {'MOCA':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/NEUROBAT_28Mar2025.csv', ['PTID','VISDATE','LIMMTOTAL', 'CLOCKSCOR', 'LDELTOTAL', 'LDELCUE', 'ANART'], {'LIMMTOTAL':np.nan, 'CLOCKSCOR':np.nan, 'LDELTOTAL':np.nan, 'LDELCUE':np.nan, 'ANART':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/CDR_28Mar2025.csv', ['PTID','VISDATE', 'CDGLOBAL'], {'CDGLOBAL':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/FAQ_28Mar2025.csv', ['PTID','VISDATE', 'FAQTOTAL'], {'FAQTOTAL':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/NPIQ_28Mar2025.csv',['PTID', 'VISDATE','NPISCORE'], {'NPISCORE':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/GDSCALE_28Mar2025.csv',['PTID','VISDATE','GDTOTAL'], {'GDTOTAL':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/MODHACH_01Apr2025.csv',['PTID', 'VISDATE','HMSCORE'], {'HMSCORE':np.nan}],\n",
    "    [f'/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/ADAS13_{datetime.datetime.now().strftime('%d%b%Y')}.csv',['PTID','VISDATE','TOTAL13'], {'TOTAL13':np.nan}],\n",
    "    [f'/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/P217_{datetime.datetime.now().strftime('%d%b%Y')}.csv',['PTID', 'EXAMDATE', 'P217_DILUTION_CORRECTED_CONC', 'P217_CV'], {'P217_DILUTION_CORRECTED_CONC': np.nan, 'P217_CV': np.nan}]\n",
    "]\n",
    "for i in range(0,len(vars)):\n",
    "    column_suffix = vars[i][0].split('/')[-1]\n",
    "    column_suffix = column_suffix.split('_')[0]\n",
    "    varnames = vars[i][1]\n",
    "    \n",
    "    #Load an allied health file\n",
    "    Talli = pd.read_csv(vars[i][0], low_memory = False)\n",
    "    Talli = Talli[vars[i][1]]\n",
    "    \n",
    "    if 'RID' in Talli.columns:\n",
    "        Talli.drop(columns = 'RID', inplace = True)    \n",
    "    print(f\"Length of {column_suffix}: {len(Talli)}\")\n",
    "    \n",
    "    #Ensure allied health file as examdate\n",
    "    if 'VISDATE' in Talli.columns:\n",
    "        Talli.rename(columns = {'VISDATE':f\"EXAMDATE_{column_suffix}\"}, inplace = True)\n",
    "        Talli[f'EXAMDATE_{column_suffix}'] = pd.to_datetime(Talli[f'EXAMDATE_{column_suffix}'], errors = 'coerce')\n",
    "    else:\n",
    "        Talli[f'EXAMDATE'] = pd.to_datetime(Talli[f'EXAMDATE'], errors = 'coerce')\n",
    "        Talli.rename(columns = {'EXAMDATE': f'EXAMDATE_{column_suffix}'}, inplace = True)\n",
    "\n",
    "    #Do a left type join\n",
    "    Tsub = pd.merge(df,Talli, on = 'PTID', how = 'left')\n",
    "    print(f\"Length of the freshly joined dataframe: {len(Tsub)}\")\n",
    "    \n",
    "    #Extract rows only with a T1 file path, so we have full rows\n",
    "    Tsub.dropna(subset='T1_PATH',inplace=True)\n",
    "    print(f\"After dropping rows without T1 paths: {len(Tsub)}\")\n",
    "\n",
    "    #Calculate abs(allied health data - MRI visit date) and label it like df.datediffs or some shit\n",
    "    try:\n",
    "        Tsub[f'DATEDIFFS_{column_suffix}'] = abs(Tsub[f'EXAMDATE_{column_suffix}'] - Tsub['VISDATE'])\n",
    "    except KeyError:\n",
    "        Tsub[f'DATEDIFFS_{column_suffix}'] = abs(Tsub['EXAMDATE'] - Tsub['VISDATE'])\n",
    "\n",
    "    #df.groupby with PTID, and then sort by datediffs ascend. Select the/a row where DATEDIFFS is the smallest\n",
    "    Tsub = Tsub.sort_values(f'DATEDIFFS_{column_suffix}', ascending=True)\n",
    "\n",
    "    print(f\"Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_{column_suffix} are at the top\") \n",
    "    min_diffs = (\n",
    "    Tsub\n",
    "    .groupby('T1_PATH')[f'DATEDIFFS_{column_suffix}']\n",
    "    .transform('min')\n",
    "    )\n",
    "    \n",
    "    Tsub = Tsub[\n",
    "    (Tsub[f'DATEDIFFS_{column_suffix}'] == min_diffs) |\n",
    "    (min_diffs.isna() & Tsub[f'DATEDIFFS_{column_suffix}'].isna())\n",
    "    ]\n",
    "\n",
    "    Tsub.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Finding rows where *EITHER* DATE_DIFFS_{column_suffix} > 28 days *OR* there is no EXAMDATE_{column_suffix} column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\") \n",
    "    mask = (Tsub[f'DATEDIFFS_{column_suffix}'] > pd.Timedelta(28, \"D\")) | (Tsub[f'EXAMDATE_{column_suffix}'].isna() == True)\n",
    "    \n",
    "    Tsub.loc[mask, f'DATEDIFFS_{column_suffix}'] = pd.NaT\n",
    "    Tsub.loc[mask, f'EXAMDATE_{column_suffix}'] = pd.NaT\n",
    "    \n",
    "    for key in vars[i][2].keys():\n",
    "        Tsub.loc[mask, key] = vars[i][2].get(key)\n",
    "    print(f'Length of database before dropping exactly identical rows = {len(Tsub)}. Tsub is of type {type(Tsub)}')\n",
    "    Tsub.drop_duplicates(keep = 'first',inplace = True)\n",
    "    print(f'Length of database after dropping rows which are exactly identical = {len(Tsub)}.')\n",
    "    \n",
    "    dupe_mask = Tsub.duplicated(subset = 'T1_PATH',keep=False)\n",
    "    Tsub_dupes = Tsub.loc[dupe_mask].copy()\n",
    "    print(f'There are {len(Tsub_dupes)} rows with identical T1 MRI file paths, from {Tsub_dupes['T1_PATH'].nunique()} different MRI scans')\n",
    "\n",
    "    def fewest_missing_one(group):\n",
    "        missing_counts = group.isna().sum(axis=1)\n",
    "        min_missing = missing_counts.min()\n",
    "        candidates = group[missing_counts == min_missing]\n",
    "        # if more than one, pick the first (or the row with smallest DATEDIFF)\n",
    "        return candidates.iloc[[0]]  # keeps only 1 row\n",
    "\n",
    "    print(\"Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\")\n",
    "    Tsub = Tsub.groupby('T1_PATH', group_keys=False).apply(fewest_missing_one, include_groups = True)\n",
    "    Tsub.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Final sanity check\n",
    "    dup_cols = [c for c in ['T1_PATH', 'MWC1T1_PATH'] if c in Tsub.columns]\n",
    "    print(f\"Final row count: {len(Tsub)}\")\n",
    "    print(f\"Remaining duplicates: {Tsub.duplicated(subset=dup_cols).sum()}\")\n",
    "    \n",
    "    # For each T1_PATH, see how many rows were kept\n",
    "    rows_per_scan = Tsub.groupby('T1_PATH').size()\n",
    "    print(rows_per_scan.value_counts())\n",
    "\n",
    "    #Make the DATEDIFFS column numeric? Just because as datetime it says 'days' at the end and I don't like that.\n",
    "    Tsub[f'DATEDIFFS_{column_suffix}'] = (Tsub[f'DATEDIFFS_{column_suffix}'].dt.days)\n",
    "    \n",
    "    print(Tsub[f'DATEDIFFS_{column_suffix}'].describe())\n",
    "    print('')\n",
    "    Tsub = Tsub.sort_values('T1_PATH').reset_index(drop=True)\n",
    "\n",
    "    Tsub.to_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/final_gregbased_scott10k_alliedhealth.csv', index = False)\n",
    "    df = Tsub\n",
    "\n",
    "Tsub.to_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/scott10k_alliedhealth.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9743afa-687e-4ca9-be03-1d333b098d42",
   "metadata": {},
   "source": [
    "### Add Amyloid data (use RID to join, and only one of the amyloid spreadsheets since the other doesn't have EXAMDATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ab453-8ad8-4a6f-a078-908ad2efbbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the freshly joined dataframe: 23927\n",
      "After dropping rows without T1 paths: 23927\n",
      "Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_AMYLOID are at the top\n",
      "Finding rows where *EITHER* DATE_DIFFS_AMYLOID > 28 days *OR* there is no EXAMDATE_AMYLOID column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\n",
      "Length of database before dropping exactly identical rows = 20903. Tsub is of type <class 'pandas.core.frame.DataFrame'>\n",
      "Length of database after dropping rows which are exactly identical = 15733.\n",
      "There are 0 rows with identical T1 MRI file paths, from 0 different MRI scans\n",
      "Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "df = pd.read_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/scott10k_alliedhealth.csv', low_memory = True)\n",
    "df['VISDATE'] = pd.to_datetime(df['VISDATE'], errors='coerce')\n",
    "\n",
    "\n",
    "vars = [\n",
    "    [f'/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/AMYLOID_{datetime.datetime.now().strftime('%d%b%Y')}.csv',\n",
    "     ['RID' ,'EXAMDATE', 'Abeta_4240_Standardized', 'Intertcept_Standardization', 'Slope_Standardization', 'Sample_volume', 'Sample_volume_UNITS', 'Abeta_42_conc', 'Abeta_42_conc_UNITS', 'Abeta_42_N14N15', 'Abeta_42_N15_ISTD_amount', 'Abeta_42_N15_ISTD_amount_UNITS', 'Abeta_40_conc', 'Abeta_40_conc_UNITS', 'Abeta_40_N14N15', 'Abeta_40_N15_ISTD_amount', 'Abeta_40_N15_ISTD_amount_UNITS', 'Abeta_4240'], \n",
    "     {'Abeta_4240_Standardized': np.nan, \n",
    "     'Intertcept_Standardization': np.nan,\n",
    "     'Slope_Standardization': np.nan,\n",
    "     'Sample_volume': np.nan,\n",
    "     'Sample_volume_UNITS': pd.NA,\n",
    "     'Abeta_42_conc': np.nan,\n",
    "     'Abeta_42_conc_UNITS': pd.NA,\n",
    "     'Abeta_42_N14N15': np.nan,\n",
    "     'Abeta_42_N15_ISTD_amount': np.nan,\n",
    "     'Abeta_42_N15_ISTD_amount_UNITS': pd.NA,\n",
    "     'Abeta_40_conc': np.nan,\n",
    "     'Abeta_40_conc_UNITS': pd.NA,\n",
    "     'Abeta_40_N14N15': np.nan,\n",
    "     'Abeta_40_N15_ISTD_amount': np.nan,\n",
    "     'Abeta_40_N15_ISTD_amount_UNITS': pd.NA,\n",
    "     'Abeta_4240': np.nan}]\n",
    "]\n",
    "for i in range(0,len(vars)):\n",
    "    column_suffix = vars[i][0].split('/')[-1]\n",
    "    column_suffix = column_suffix.split('_')[0]\n",
    "    varnames = vars[i][1]\n",
    "    \n",
    "    #Load an allied health file\n",
    "    Talli = pd.read_csv(vars[i][0], low_memory = False)\n",
    "    Talli = Talli[vars[i][1]]\n",
    "    \n",
    "    #Ensure allied health file as examdate\n",
    "    Talli[f'EXAMDATE'] = pd.to_datetime(Talli[f'EXAMDATE'], errors = 'coerce')\n",
    "    Talli.rename(columns = {'EXAMDATE': f'EXAMDATE_{column_suffix}'}, inplace = True)\n",
    "\n",
    "    #Do a left type join\n",
    "    Tsub = pd.merge(df, Talli, on = 'RID', how = 'left')\n",
    "    print(f\"Length of the freshly joined dataframe: {len(Tsub)}\")\n",
    "    \n",
    "    #Extract rows only with a T1 file path, so we have full rows\n",
    "    Tsub.dropna(subset='T1_PATH',inplace=True)\n",
    "    print(f\"After dropping rows without T1 paths: {len(Tsub)}\")\n",
    "\n",
    "    #Calculate abs(allied health data - MRI visit date) and label it like df.datediffs or some shit\n",
    "    Tsub[f'DATEDIFFS_{column_suffix}'] = abs(Tsub[f'EXAMDATE_{column_suffix}'] - Tsub['VISDATE'])\n",
    "\n",
    "    #df.groupby with PTID, and then sort by datediffs ascend. Select the/a row where DATEDIFFS is the smallest\n",
    "    Tsub = Tsub.sort_values(f'DATEDIFFS_{column_suffix}', ascending=True)\n",
    "\n",
    "    print(f\"Grouping rows by 'T1_PATH'. Within groups, organising rows so smallest DATE_DIFFS_{column_suffix} are at the top\") \n",
    "    min_diffs = (\n",
    "    Tsub\n",
    "    .groupby('T1_PATH')[f'DATEDIFFS_{column_suffix}']\n",
    "    .transform('min')\n",
    "    )\n",
    "    \n",
    "    Tsub = Tsub[\n",
    "    (Tsub[f'DATEDIFFS_{column_suffix}'] == min_diffs) |\n",
    "    (min_diffs.isna() & Tsub[f'DATEDIFFS_{column_suffix}'].isna())\n",
    "    ]\n",
    "\n",
    "    Tsub.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Finding rows where *EITHER* DATE_DIFFS_{column_suffix} > 28 days *OR* there is no EXAMDATE_{column_suffix} column. If that's the case, replace the relevant values with NaNs, NaTs and pd.NAs\") \n",
    "    mask = (Tsub[f'DATEDIFFS_{column_suffix}'] > pd.Timedelta(28, \"D\")) | (Tsub[f'EXAMDATE_{column_suffix}'].isna() == True)\n",
    "    \n",
    "    Tsub.loc[mask, f'DATEDIFFS_{column_suffix}'] = pd.NaT\n",
    "    Tsub.loc[mask, f'EXAMDATE_{column_suffix}'] = pd.NaT\n",
    "    \n",
    "    for key in vars[i][2].keys():\n",
    "        Tsub.loc[mask, key] = vars[i][2].get(key)\n",
    "\n",
    "    print(f'Length of database before dropping exactly identical rows = {len(Tsub)}. Tsub is of type {type(Tsub)}')\n",
    "    Tsub.drop_duplicates(keep = 'first',inplace = True)\n",
    "    print(f'Length of database after dropping rows which are exactly identical = {len(Tsub)}.')\n",
    "    \n",
    "    dupe_mask = Tsub.duplicated(subset = 'T1_PATH',keep=False)\n",
    "    Tsub_dupes = Tsub.loc[dupe_mask].copy()\n",
    "    print(f'There are {len(Tsub_dupes)} rows with identical T1 MRI file paths, from {Tsub_dupes['T1_PATH'].nunique()} different MRI scans')\n",
    "\n",
    "    def fewest_missing_one(group):\n",
    "        missing_counts = group.isna().sum(axis=1)\n",
    "        min_missing = missing_counts.min()\n",
    "        candidates = group[missing_counts == min_missing]\n",
    "        # if more than one, pick the first (or the row with smallest DATEDIFF)\n",
    "        return candidates.iloc[[0]]  # keeps only 1 row\n",
    "\n",
    "    print(\"Grouping rows by T1_PATH, finding the rows with the fewest missing values. If it's a tie between two rows, the first one for each T1_PATH group is kept\")\n",
    "    Tsub = Tsub.groupby('T1_PATH', group_keys=False).apply(fewest_missing_one, include_groups = True)\n",
    "    Tsub.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Final sanity check\n",
    "    dup_cols = [c for c in ['T1_PATH', 'MWC1T1_PATH'] if c in Tsub.columns]\n",
    "    print(f\"Final row count: {len(Tsub)}\")\n",
    "    print(f\"Remaining duplicates: {Tsub.duplicated(subset=dup_cols).sum()}\")\n",
    "    \n",
    "    # For each T1_PATH, see how many rows were kept\n",
    "    rows_per_scan = Tsub.groupby('T1_PATH').size()\n",
    "    print(rows_per_scan.value_counts())\n",
    "\n",
    "    #Make the DATEDIFFS column numeric? Just because as datetime it says 'days' at the end and I don't like that.\n",
    "    Tsub[f'DATEDIFFS_{column_suffix}'] = (Tsub[f'DATEDIFFS_{column_suffix}'].dt.days)\n",
    "    \n",
    "    print(Tsub[f'DATEDIFFS_{column_suffix}'].describe())\n",
    "    print('')\n",
    "    Tsub = Tsub.sort_values('T1_PATH').reset_index(drop=True)\n",
    "\n",
    "    Tsub.to_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/withamyloid_gregbased_scott10k_alliedhealth.csv', index = False)\n",
    "    df = Tsub\n",
    "\n",
    "Tsub.to_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/debug_scott10k_alliedhealth.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca27a36-ac49-4f2c-9a1a-ea74a0395623",
   "metadata": {},
   "source": [
    "### Checking diagnoses of scans in Scott 10K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a315e-a6bc-4f8f-b19a-9e20621a2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/debug_scott10k_alliedhealth.csv', low_memory = False)\n",
    "\n",
    "print(df['DIAGNOSIS'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8865e36-8018-42e2-8768-5162ee0a6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rsync -av /rds/general/project/c3nl_scott_students/ephemeral/sankeith/debug_scott10k_alliedhealth.csv /rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott10k_alliedhealth.csv\n",
    "cd /rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping\n",
    "git add scott10k_alliedhealth.csv\n",
    "dategcp=\"`date +%d%b%Y`\"\n",
    "datetime=\"`date +%H%M%S`\"\n",
    "message=\"Remade Scott 10K allied health database: ${dategcp}, ${datetime}\"\n",
    "\n",
    "git commit -a -m \"$message\"\n",
    "git push -u origin main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_1)",
   "language": "python",
   "name": "venv_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
