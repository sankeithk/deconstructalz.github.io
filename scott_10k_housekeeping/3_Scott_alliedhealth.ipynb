{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58121587-a87c-4e36-a8bc-0c751fe7a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7aad724-e57b-4bce-96f9-29febf3faa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As what greg did###\n",
    "#1. Load an allied health file\n",
    "#2. Ensure allied health file as examdate\n",
    "#3. Do a right type join (assume left = og file, right = allied health file)\n",
    "#4. Extract rows only with a T1 file path, so we have full rows\n",
    "#5. Calculate abs(allied health data - MRI visit date) and label it like df.datediffs or some shit\n",
    "#6. df.groupby with PTID, and then sort by datediffs ascend\n",
    "#7. Keep the row where datadiff is less than 28 days and the smallest val. If tie, then we ball and just choose at random\n",
    "#8. Conduct a final length of rows check - MUST BE 15733\n",
    "#9. Rinse and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d12bd853-1c75-426b-a613-8b6fad00872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15733\n",
      "14\n",
      "2635\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/gregbased_scott10k_alliedhealth.csv', low_memory = False)\n",
    "df[f'VISDATE'] = pd.to_datetime(df[f'VISDATE'])\n",
    "df[f'EXAMDATE_4WKS_LATER'] = pd.to_datetime(df[f'EXAMDATE_4WKS_LATER'])\n",
    "df[f'EXAMDATE_4WKS_B4'] = pd.to_datetime(df[f'EXAMDATE_4WKS_B4'])\n",
    "print(len(df))\n",
    "print(len(df.columns))\n",
    "print(len(df['PTID'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4306698e-5f45-43a4-a6bb-a82f8b6d7b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of DXSUM: 15674\n",
      "Length of the freshly joined dataframe: 112212\n",
      "After dropping rows without T1 paths: 112212\n",
      "15811\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "15772\n",
      "count                        11967\n",
      "mean     8 days 03:34:47.440461268\n",
      "std      7 days 19:34:22.459119784\n",
      "min                0 days 00:00:00\n",
      "25%                1 days 00:00:00\n",
      "50%                6 days 00:00:00\n",
      "75%               14 days 00:00:00\n",
      "max               28 days 00:00:00\n",
      "Name: DATEDIFFS_DXSUM, dtype: object\n",
      "             PTID     RID                                  DATA_KEY  T1_YEAR  \\\n",
      "938    123_S_0108   108.0  123_S_0108_ADNI-T1_2011-02-15_08_58_12.0   2011.0   \n",
      "939    123_S_0108   108.0  123_S_0108_ADNI-T1_2011-02-15_08_58_12.0   2011.0   \n",
      "2994   128_S_1407  1407.0  128_S_1407_ADNI-T1_2012-01-03_15_26_25.0   2012.0   \n",
      "2995   128_S_1407  1407.0  128_S_1407_ADNI-T1_2012-01-03_15_26_25.0   2012.0   \n",
      "3006   128_S_1407  1407.0  128_S_1407_ADNI-T1_2012-01-03_15_18_42.0   2012.0   \n",
      "...           ...     ...                                       ...      ...   \n",
      "14790  053_S_4661  4661.0  053_S_4661_ADNI-T1_2012-09-11_15_06_25.0   2012.0   \n",
      "14884  099_S_4202  4202.0  099_S_4202_ADNI-T1_2012-01-09_06_25_13.0   2012.0   \n",
      "14892  099_S_4202  4202.0  099_S_4202_ADNI-T1_2012-01-09_06_25_13.0   2012.0   \n",
      "15086  153_S_2109  2109.0  153_S_2109_ADNI-T1_2011-02-02_09_19_17.0   2011.0   \n",
      "15087  153_S_2109  2109.0  153_S_2109_ADNI-T1_2011-02-02_09_19_17.0   2011.0   \n",
      "\n",
      "       T1_MON  T1_DAY    VISDATE EXAMDATE_4WKS_LATER EXAMDATE_4WKS_B4  \\\n",
      "938       2.0    15.0 2011-02-15          2011-03-15       2011-01-18   \n",
      "939       2.0    15.0 2011-02-15          2011-03-15       2011-01-18   \n",
      "2994      1.0     3.0 2012-01-03          2012-01-31       2011-12-06   \n",
      "2995      1.0     3.0 2012-01-03          2012-01-31       2011-12-06   \n",
      "3006      1.0     3.0 2012-01-03          2012-01-31       2011-12-06   \n",
      "...       ...     ...        ...                 ...              ...   \n",
      "14790     9.0    11.0 2012-09-11          2012-10-09       2012-08-14   \n",
      "14884     1.0     9.0 2012-01-09          2012-02-06       2011-12-12   \n",
      "14892     1.0     9.0 2012-01-09          2012-02-06       2011-12-12   \n",
      "15086     2.0     2.0 2011-02-02          2011-03-02       2011-01-05   \n",
      "15087     2.0     2.0 2011-02-02          2011-03-02       2011-01-05   \n",
      "\n",
      "                                                 T1_PATH  \\\n",
      "938    /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "939    /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "2994   /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "2995   /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "3006   /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "...                                                  ...   \n",
      "14790  /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "14884  /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "14892  /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "15086  /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "15087  /rds/general/project/scott_data_adni/live/ADNI...   \n",
      "\n",
      "                                             MWC1T1_PATH  PTGENDER  \\\n",
      "938    /rds/general/project/c3nl_scott_students/live/...       1.0   \n",
      "939    /rds/general/project/c3nl_scott_students/live/...       1.0   \n",
      "2994   /rds/general/project/c3nl_scott_students/live/...       2.0   \n",
      "2995   /rds/general/project/c3nl_scott_students/live/...       2.0   \n",
      "3006   /rds/general/project/c3nl_scott_students/live/...       2.0   \n",
      "...                                                  ...       ...   \n",
      "14790  /rds/general/project/c3nl_scott_students/live/...       1.0   \n",
      "14884  /rds/general/project/c3nl_scott_students/live/...       1.0   \n",
      "14892  /rds/general/project/c3nl_scott_students/live/...       1.0   \n",
      "15086  /rds/general/project/c3nl_scott_students/live/...       1.0   \n",
      "15087  /rds/general/project/c3nl_scott_students/live/...       1.0   \n",
      "\n",
      "             PTDOB  PTEDUCAT   EXAMDATE   PHASE  DIAGNOSIS DATEDIFFS_DXSUM  \n",
      "938    01-Oct-1927      18.0 2011-02-15   ADNI2        3.0          0 days  \n",
      "939    01-Oct-1927      18.0 2011-02-15  ADNIGO        3.0          0 days  \n",
      "2994   01-Oct-1932      16.0 2012-01-04  ADNIGO        3.0          1 days  \n",
      "2995   01-Oct-1932      16.0 2012-01-04   ADNI2        3.0          1 days  \n",
      "3006   01-Oct-1932      16.0 2012-01-04   ADNI2        3.0          1 days  \n",
      "...            ...       ...        ...     ...        ...             ...  \n",
      "14790  01-Aug-1938      18.0 2012-06-18     NaN        NaN             NaT  \n",
      "14884  01-Feb-1941      18.0 2012-04-09     NaN        NaN             NaT  \n",
      "14892  01-Feb-1941      18.0 2011-10-10     NaN        NaN             NaT  \n",
      "15086  01-Jul-1935      14.0 2011-05-20     NaN        NaN             NaT  \n",
      "15087  01-Jul-1935      14.0 2010-10-18     NaN        NaN             NaT  \n",
      "\n",
      "[78 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "vars = [\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/DXSUM_10Sep2025.csv',['PTID','EXAMDATE','PHASE', 'DIAGNOSIS'], {'PHASE':np.nan,'DIAGNOSIS':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/MMSE_28Mar2025.csv', ['PTID','VISDATE','MMSCORE'], {'MMSCORE':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/GDSCALE_28Mar2025.csv',['PTID','VISDATE','GDTOTAL'], {'GDTOTAL':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/MOCA_30Mar2025.csv', ['PTID','VISDATE', 'MOCA'], {'MOCA':np.nan}],\n",
    "    ['/rds/general/project/c3nl_scott_students/live/sankeith/scott_10k_housekeeping/scott_10k_extra_adni_info/NEUROBAT_28Mar2025.csv', ['PTID','VISDATE','LIMMTOTAL', 'CLOCKSCOR', 'LDELTOTAL', 'LDELCUE', 'ANART'], {'LIMMTOTAL':np.nan, 'CLOCKSCOR':np.nan, 'LDELTOTAL':np.nan, 'LDELCUE':np.nan, 'ANART':np.nan}]\n",
    "]\n",
    "for i in range(0,len(vars)):\n",
    "    column_suffix = vars[i][0].split('/')[-1]\n",
    "    column_suffix = column_suffix.split('_')[0]\n",
    "    varnames = vars[i][1]\n",
    "    \n",
    "    #Load an allied health file\n",
    "    Talli = pd.read_csv(vars[i][0], low_memory = False)\n",
    "    Talli = Talli[vars[i][1]]\n",
    "    \n",
    "    if 'RID' in Talli.columns:\n",
    "        Talli.drop(columns = 'RID', inplace = True)    \n",
    "    print(f\"Length of {column_suffix}: {len(Talli)}\")\n",
    "    \n",
    "    #Ensure allied health file as examdate\n",
    "    if 'VISDATE' in Talli.columns:\n",
    "        Talli.rename(columns = {'VISDATE':f\"EXAMDATE_{column_suffix}\"}, inplace = True)\n",
    "        Talli[f'EXAMDATE_{column_suffix}'] = pd.to_datetime(Talli[f'EXAMDATE_{column_suffix}'], errors = 'coerce')\n",
    "    else:\n",
    "        Talli[f'EXAMDATE'] = pd.to_datetime(Talli[f'EXAMDATE'], errors = 'coerce')\n",
    "\n",
    "    #Do a right type join\n",
    "    Tsub = pd.merge(df,Talli, on = 'PTID', how = 'left')\n",
    "    print(f\"Length of the freshly joined dataframe: {len(Tsub)}\")\n",
    "    \n",
    "    #Extract rows only with a T1 file path, so we have full rows\n",
    "    Tsub.dropna(subset='T1_PATH',inplace=True)\n",
    "    print(f\"After dropping rows without T1 paths: {len(Tsub)}\")\n",
    "\n",
    "    #Calculate abs(allied health data - MRI visit date) and label it like df.datediffs or some shit\n",
    "    try:\n",
    "        Tsub[f'DATEDIFFS_{column_suffix}'] = abs(Tsub[f'EXAMDATE_{column_suffix}'] - Tsub['VISDATE'])\n",
    "    except KeyError:\n",
    "        Tsub[f'DATEDIFFS_{column_suffix}'] = abs(Tsub['EXAMDATE'] - Tsub['VISDATE'])\n",
    "\n",
    "    #df.groupby with PTID, and then sort by datediffs ascend. Select the/a row where DATEDIFFS is the smallest\n",
    "    Tsub = Tsub.sort_values(f'DATEDIFFS_{column_suffix}', ascending=True)\n",
    "    \n",
    "    min_diffs = (\n",
    "    Tsub\n",
    "    .groupby('T1_PATH')[f'DATEDIFFS_{column_suffix}']\n",
    "    .transform('min')\n",
    "    )\n",
    "    \n",
    "    Tsub = Tsub[\n",
    "    (Tsub[f'DATEDIFFS_{column_suffix}'] == min_diffs) |\n",
    "    (min_diffs.isna() & Tsub[f'DATEDIFFS_{column_suffix}'].isna())\n",
    "    ]\n",
    "\n",
    "    Tsub.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    mask = Tsub[f'DATEDIFFS_{column_suffix}'] > pd.Timedelta(28, \"D\")\n",
    "    \n",
    "    Tsub.loc[mask, f'DATEDIFFS_{column_suffix}'] = pd.NaT\n",
    "    \n",
    "    for key in vars[i][2]:\n",
    "        Tsub.loc[mask, key] = vars[i][2].get(key)\n",
    "\n",
    "    print(len(Tsub))\n",
    "    print(type(Tsub))\n",
    "    Tsub.drop_duplicates(keep = 'first',inplace = True)\n",
    "    print(len(Tsub))\n",
    "    print(Tsub[f'DATEDIFFS_{column_suffix}'].describe())\n",
    "    \n",
    "    dupe_mask = Tsub.duplicated(subset='T1_PATH', keep=False)\n",
    "    Tsub_dupes = Tsub.loc[dupe_mask].copy()\n",
    "    print(Tsub_dupes)\n",
    "    Tsub_dupes.to_csv(f'/rds/general/project/c3nl_scott_students/ephemeral/sankeith/final_gregbased_scott10k_alliedhealth_{i}.csv', index = False)\n",
    "\n",
    "\n",
    "    Tsub.to_csv('/rds/general/project/c3nl_scott_students/ephemeral/sankeith/final_gregbased_scott10k_alliedhealth.csv', index = False)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4432e1f2-816b-4564-b67f-78e21bfe4ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2635"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_1)",
   "language": "python",
   "name": "venv_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
